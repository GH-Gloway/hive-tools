<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
 
<configuration>
    <property>
        <name>local.realm</name>
        <value>HADOOP.HZ.NETEASE.COM</value>
    </property>
 
    <!-- file system properties -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://mycluster</value>
        <description>The
            name of the default file system. Either the literal string "local" or a host:port
            for NDFS. </description>
        <final>true</final>
    </property>

    <property>
        <name>fs.defaultFS.hadoop353</name>
        <value>hdfs://mycluster</value>
        <description>The
            name of the default file system. Either the literal string "local" or a host:port
            for NDFS. </description>
        <final>true</final>
    </property>

     <property>
        <name>fs.defaultFS.binjiang</name>
        <value>hdfs://hz-cluster1</value>
        <description>The
            name of the default file system. Either the literal string "local" or a host:port
            for NDFS. </description>
        <final>true</final>
    </property>
	<property>
        <name>fs.defaultFS.xiaoshan</name>
        <value>hdfs://hz-cluster2</value>
        <description>The
            name of the default file system. Either the literal string "local" or a host:port
            for NDFS. </description>
        <final>true</final>
    </property>
     <property>
        <name>fs.defaultFS.liantong</name>
        <value>hdfs://hz-cluster3</value>
        <description>The
            name of the default file system. Either the literal string "local" or a host:port
            for NDFS. </description>
        <final>true</final>
    </property>

    <property>
        <name>ha.zookeeper.quorum</name>
        <value>hadoop353.lt.163.org:2181,hadoop354.lt.163.org:2182,hadoop357.lt.163.org:2181</value>
    </property>
 
    <!-- add LZO,LZ4 compression support -->
    <property>
        <name>io.compression.codecs</name>
        <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.Lz4Codec,org.apache.hadoop.io.compress.SnappyCodec</value>
    </property>
 
    <property>
        <name>io.compression.codec.lzo.class</name>
        <value>com.hadoop.compression.lzo.LzoCodec</value>
    </property>
 
    <property>
        <name>fs.trash.interval</name>
        <value>1440</value>
        <description>Number of minutes between trash checkpoints.
            If zero, the trash feature is disabled.
        </description>
    </property>
 
    <!-- Web Interface Configuration -->
    <property>
        <name>webinterface.private.actions</name>
        <value>false</value>
        <description> If set to true, the web interfaces of JT and NN may
            contain
            actions, such as kill job, delete file, etc., that should
            not be exposed to public. Enable this option if the interfaces
            are only reachable by those who have the right authorization.
        </description>
    </property>
 
    <property>
        <name>hadoop.security.authentication</name>
        <value>kerberos</value>
        <description>
            Set the authentication for the cluster. Valid values are: simple or
            kerberos.
        </description>
    </property>
 
    <property>
        <name>hadoop.security.authorization</name>
        <value>true</value>
        <description>
            Enable authorization for different protocols.
        </description>
    </property>
 
    <property>
        <name>hadoop.security.groups.cache.secs</name>
        <value>14400</value>
    </property>
 
    <property>
        <name>hadoop.kerberos.kinit.command</name>
        <value>/usr/bin/kinit</value>
    </property>
 
    <!-- Authentication for Hadoop HTTP web-consoles -->
    <property>
        <name>hadoop.http.filter.initializers</name>
        <value>org.apache.hadoop.security.AuthenticationFilterInitializer</value>
    </property>
 
    <property>
        <name>hadoop.http.authentication.type</name>
        <value>kerberos</value>
    </property>
 
    <property>
        <name>hadoop.http.authentication.token.validity</name>
        <value>36000</value>
    </property>
 
    <property>
        <name>hadoop.http.authentication.signature.secret.file</name>
        <value>/home/hadoop/yarn/conf/http-secret</value>
        <description>
            The signature secret for signing the authentication tokens.
            If not set a random secret is generated at startup time.
            The same secret should be used for JT/NN/DN/TT configurations.
        </description>
    </property>
 
    <property>
        <name>hadoop.http.authentication.cookie.domain</name>
        <value>${local.realm}</value>
    </property>
 
    <property>
        <name>hadoop.http.authentication.simple.anonymous.allowed</name>
        <value>false</value>
    </property>
 
    <property>
        <name>hadoop.http.authentication.kerberos.principal</name>
        <value>HTTP/_HOST@${local.realm}</value>
    </property>
 
    <property>
        <name>hadoop.http.authentication.kerberos.keytab</name>
        <value>/home/hadoop/yarn/conf/http.keytab</value>
    </property>
 
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/tmp/hadoop-apple</value>
    </property>
 
    <property>
        <name>io.bytes.per.checksum</name>
        <value>4096</value>
    </property>
 
    <property>
        <name>fs.inmemory.size.mb</name>
        <value>200</value>
    </property>
 
    <property>
        <name>io.file.buffer.size</name>
        <value>131072</value>
    </property>
 
    <property>
        <name>hadoop.proxyuser.mapred.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.mapred.groups</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hive.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hive.groups</name>
        <value>*</value>
    </property>

    <property>
        <name>hadoop.proxyuser.hadoop.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hadoop.groups</name>
        <value>*</value>
    </property>
 
</configuration>

